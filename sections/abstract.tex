\thispagestyle{empty}\section*{\ifthenelse{\boolean{english}}{Abstract}{Zusammenfassung}}
% 188 tokens
How can the sample efficiency of decision making in autonomous driving be improved? This thesis provides an answer by combining \gls{rl} with \gls{mcts}. The proposed algorithm plans cooperative trajectories for scenarios with a flexible number of agents through a novel neural network architecture. Agent interactions are modeled using a Transformer encoder. Exploiting the limited information from their own viewpoint, agents are able to generate predictions for other vehicles. The method builds on an AlphaZero-extension for continuous action spaces (A0C) by formulating a multi-agent training objective. Its policy enforces action bounds through a mixture model of transformed normal distributions.

The proposed algorithm is evaluated against an \gls{mcts} augmented with domain-specific heuristics. In a challenging driving scenario, the method is able to outperform the baseline in terms of sample efficiency and planning speed. In another scenario, the algorithm is able to recover the heuristic knowledge of the \gls{mcts} while learning tabula rasa. Ablation studies highlight important design choices and provide insights into the significance of the method's components. Finally, a comprehensive analysis illuminates the generalization capabilities of learned networks and highlights the potential of methods combining learning with planning and heuristics.