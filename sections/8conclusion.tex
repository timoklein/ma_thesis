\glsresetall
\section{Conclusion}\label{sec:conclusion}
%Overview
This thesis presents an approach for guiding the sampling of a \gls{mcts} based planner through a neural network learned by \gls{rl}. The model is able to succesfully predict maneuvers in a continuous action space via learned proposal distributions. As the planner is used in cooperative multi-agent driving scenarios, a novel network based on the Transformer architecture is developed. It is able to learn interactions between a flexible number of agents from a hybrid numerical and visual input representation. An empirical evaluation shows that the proposed approach is able to improve sample efficiency and wall clock speed in a challenging multi-agent driving scenario over a pure \gls{mcts} baseline.

% Contribution
Interpreting the agents within a scenario as a sequence of objects allows the application of a Transformer encoder to learn interactions between a flexible number of agents. This newly developed network architecture is trained starting from \emph{tabula rasa} by extending the loss function of an AlphaZero-inspired algorithm (A0C) to multi-agent settings. Action bounds are enforced by using a policy consisting of mixtures of transformed normal distributions. Once trained, the network is able to effectively predict trajectories for all vehicles in a scenario using only the incomplete sensory input of a single agent.

% Results
An empirical analysis shows that the guided search using a neural network is able to successfully recover the performance of a baseline augmented with domain-specific heuristics. In a more challenging scenario, the proposed approach achieves competitive results to the \gls{mcts} while using $8 \times$ fewer iterations and less wall clock time. Experiments disclose a stable learning process for a variety of modifications. Additional ablation studies reveal that learning in continuous domains is driven by the policy objective, which is in contrast to existing findings in board games. The networks trained by the proposed algorithm are able to generalize knowledge to unseen scenarios with some success and improve substantially over a random network. Finally, augmenting the guided search with heuristics yields a method with the strongest overall performance and a high success rate on all but one task.